
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Generative AI for Everyone</title>
    </head>
    <body>
        <pre>Week 1 Introduction:
	After release of Chat GPT by OpenAI, Generative AI become more popular and everyone aware of it. There are lot of advantages in all over the fields.
	It is generative and interactive, it can able to solve and give solutions to various fields. So, that lot of works will become easier. After entry of 
		Chat GPT, it can add 2.6 - 4.4 trillion dollars annually to the economy. Over 20% of workers job can be impacted by 50% by using generative AI. 
		So, there may be lot of jobs replaced and job loss will happen. Some misunderstanding are there due to over hype. In this course, we will get 
		clear idea of What is generative AI, what can and can't do?
	What is Generative AI:
		Artificial Intelligence system that can produce high quality content specifically text, images, audio.
		Most commonly known generative AI is ChatGPT, which can give text results and in the type of prompt way. Other generative AI are Google and Bing etc.
			Other companies are also providing the same results.
		Generative AI as a developer tool is going to make the major impact.
		We are using AI in our daily life without knowing. Some of the examples:
			Web search - Google, Bing
			Fraud detection - Credit card payments
			Recommender system - Amazon, Netflix
	Many complex AI applications are difficult to build earlier, but generative AI makes it much easier now. So, number of AI products are increased.
	Applications of Generative AI:
		Text, Images, Audio and Video Generation
		
How Generative AI works:
	After usage of ChatGPT and Bard, the text generation is looks magical and created a new path for upcoming AI revolutions. Let's see how generative AI works.
	Most common Tools used in AI are Supervised Learning and Generative AI.
	Supervised learning means input to output mapping. (Labeling)
	Applications of supervised learning are spam filtering, online advertising, self-driving car, Healthcare, Visual inspection, Speech recognition.
	Performance of supervised learning models are high with larger data compared with smaller data models.
	
	Generating Text using Large Language Model(LLM):
		LLMs are build with supervised learning to repeatedly predict next word.
		Eg. My favourite food is a bangle with cream cheese.
	When we train a very large AI system on a lot of data(billion of data), we will get a Large Language Model like ChatGPT.
	
LLMs as a thought partner:
	Let see example how LLM model like chat GPT are used.
	A new way of find information: able to answer the basic question based on the context.
	Writing Partner: able to rewrite the content clear and understandable, write an essay for me.
	Web search or LLM model:
		Web search will give the websites related to query.
		LLM model will give the exact answer searched from multiple websites.
		Eg. solution for injured leg, pineapple pie recipe, coffee infused pineapple pie recipe.
	It is depends on the use case if we need detail of exact question, then we can go llm model, otherwise go for web search.
	
AI is a general purpose technology:
	Generative AI can be used in multiple places hence it is called as general purpose technology. It is like electricity, we can use it for multiple 
		purposes. Like supervised learning, used in multiple applications in the above. Same is for Gen AI also.
	Some of the Applications:
		Writing,
		Reading,
		Chatting.
	Writing can be used in llm model like chatGPT or Bard, Bing etc..
	Reading can be used in reviewing the email whether it is complaint or not.
	Chatting can be used in chat bot applications for conversational purpose.
	
	It can used as web-based or software-based application. Web-based applications are chatGPT, Bard, Bing. Software-based applications are email routing,
		document searching.
	
Generative AI applications:
	Writing:
		It can able to answer any types of questions:
			Brainstorming ideas,
			Developing sales strategy,
			Writing a press report,
			Translation,
			etc...
	Reading: 
		Writing will get small input and give large output. Reading will get large input and give small output.
		Used in:
			Proofreading - spelling and grammatical correction,
			Summarizing Article - summarizing a large story to some 100 to 200 words,
			Summarizing Conversation - summarizing conversation that help manager to understand the problem without reading whole chat in telecom,
			Email routing - asking the proper detailed prompt to understand better with the question to route correctly,
			Reputation Monitoring - Dashboard to understand the customer sentiment over time.
	Chatting:
		Normally, chatbots are aware of all the topics. But using generative AI, we are creating specilized chatbots. Specialized chatbots are focused 
			on particular topic and answer the questions.
		Some specialized chatbots are Trip planner, Career coach, Recipe advisor etc.
		Now all the companies are creating the chatbot for their applications for own purpose with specialized contents.
		Some are with IT service chatbots which can perform actions based on request. Eg. I will change the password, sent OTP to mobiles etc...
		The rise of chatbot in customer services:
			Human Only -> Humans with robots -> Human and robots -> Robots only.
		Advice for deploying chatbots:
			Start with internal-facing chatbot,
			Deploy with human-in-the-loop to check their mistakes,
			After all the tests, finally send the chatbot to direct communication with customer.
		
What LLMs can and can't do:
	What prompting an LLM can do: a task given to fresh college student to perform as a prompt. Even if the task can't understand by student, still LLM 
		gives the proper answers.
	Knowledge cutoff: Knowledge of LLM models are till the day of training. It don't know the latest news or information.
	Hallucinations:	Sometimes even we ask for unhappened things, it will give the details about it. Eg. Lawyer in UI used ChatGPT and submitted the case.
	Input and output prompt content are limited. Content are limited to few thousands.
	Generative AI won't work well in tabular data. But It works well in unstructured data like text, images, audio and video.
	Bias and Toxicity: Bias means if we ask about doctor, it consider as man. If we ask about nurse, it consider as woman. And also should care about harm
		words or context generated by AI.
	
Tips for prompting:
	Be clear, specific and descriptive.
	Guide the model to think through its answer.
	Experiment and iterate.
	
	Iteratively improve the prompt:
		Idea, Prompt, LLM response. All are comes in loop for the effective prompting.
	
	Steps:
		Ask a prompt,
		if the response is not clear and correct,
		change the idea of prompt,
		if the response is improved or not,
		change the idea of prompt till we get the expected response.
		
	Be careful with:
		confidential information or documents,
		whether you trust the LLM response, don't trust the LLM response blindly(Eg. Lawyer used chatGPT for a case)

Image Generation(Optional):
	Some models are work with both text and images generation. Such model are multimodels.
	The concept behind image generation is Supervised learning. It is same as text model training with a sentence to predict next word.
	When we give an image to train a model, it use diffusion model, which converts the clear image in multiple stage of unclear images. Later, model is
		uncleared image to predict the clear image in every stages. Last stage of unclear image is a random image.
	In prompt when we ask for apple image, the model get the text prompt along with trained images will start to predict the apple image with the help 
		of text from unclear random image to clear final image of apple.
	
Week 2 Introduction:
Software application:
Using generative AI in software applications:
	Before Gen AI, software industries were used write, read and chat application using supervised learning. In Supervised Learning, we have to collect 
		data, train model, validate model, deployment in env. Time taken to collect, train, validate and deploy will take more time like 6-12 months depends
		on the size and quality of data. Coding of data read, formatting, data cleaning, feature engineering, model testing and various lines of codes were
		used to perform such operations.
	After Gen AI, We have LLM model, we just need to call the llm model with our prompt, that's it. It doesn't require much coding also, 3-4 line of code is
		enough. By the advantage of this, it reduces the time of developers to create a chat like application in fast and easy way.

Lifecycle of a generative AI project:
	Developing generative AI project is an experimental and iterative process.
	Steps:
		Scope - know the objective of the project.
		Build/Improve system - start develop a prototype and improve it later for the final one. This process can be done in 1-2 weeks.
		Internal evaluation - evaluate the performance of the model internally and if any incorrect response give, go to previous stage to improve model.
		Deploy and monitor - deploy in production to interact with external person and evaluate performance continuously to improve model by correcting 
			both Build and internal evaluation. 
		Eg. My miso ramen tasted like tonkotsu ramen. This is the japanese food, both are different one, but the response is giving as positive. Like this,
			model sometimes can give wrong response. We have to correct it.
	Tips to improve performance:
		Building Gen AI is a highly experimental process. we have to repeat and fix it.
		Prompting - idea, prompt, llm response.
		Retrieval Augmented Generation (RAG) - Give llm access to external data resources.
		Fine-tune models - adapt llm to your task.
		Pretrain model - Train model from scratch.

Cost Intuition:
	Explain a details of how and how much cost of generative AI models are charged.
	Some models are OpenAI/GPT3.5, OpenAI/GPT4, Google/PaLM2, Amazon/Titan lite.
	what is a token? Cost of tokens. Example of average reading speed of human and 15,000 input and output tokens and average cost of $0.08 cent is used.
	
Advanced Technology beyond prompting:
Retrieval Augmented Generation(RAG):
	Generally, Gen AI is a knowledge source which has lot of information about all the things, but not indepth knowledge of everything.
	Eg. if we ask the parking details of our company, it will replies as I need more information to answer.
	To solve this issue, we will give the details of our company to learn about our company and answer according to the question. That time, It will give
		proper answer.
	General chatbot don't know about company details, but General chatbot with RAG know about company details.
	RAG will work as the task given to me to solve multiple template problem.
	When we give many documents to train, then we ask about the question. It will search for relevant document first, then it select the relevant document
		as a system prompt and question asked as user prompt.
	Examples of RAG applications:
		Chat with PDF files - there are many applications now to have conversation with pdf files. Once we upload the pdf file and ask the question, it 
			will give the answer based on the pdf loaded.
		Answer question based on a website's article - coursera, snapchat like companies having chatbot which help the user to the solve their doubts on the
			companies applications.
		New form of search engine - microsoft bing, google and you.com are having search engine which is working as chatbot with RAG approach.
		Big idea - LLM as a reasoning engine:
			LLMs have lot of general knowledge, but they don't have everything.
			By providing relevant context in the prompt, we ask an LLM to read a piece of text, then process it to an answer.
			We are using it as a reasoning engine to process information, rather than using as a source of information.
		
Fine tuning:
	It is another way of getting more relevant information from the model.
	In this, we can tune the number of input and output text, type of style that the answer should respond.
	Generally, LLM models are pretrained with 100B of words to predict next word. Fine tuning means training a model with relevant information with 1000
		to 10,000 words. So, the model response will be depends on the relevant information, not from the 100B of words. The response will accurate as the
		model trained with data.
	Reason for fine tuning:
		To carry out a task that isn't easy to define in a prompt:
			To summarize in certain style or structure. Eg. customer conversation to get summary in specific format to understand more about it.
			To mimicking a writing or speaking style. Eg. writing a para like me which will be pretrained and fine tuned with my para. then it will respond
				in my style.		
		To Help LLM to gain specific knowledge:
			Medical notes, Legal documents, Financial documents etc which will be trained with very lesser data. So, fine tuning will give more formal way
				of response according to field.
		To get a smaller model to perform a task:
			Sometimes smaller model will perform better than than larger model, because larger model has wide knowledge. So, the answer will not specific 
				but when we fine tune with smaller model with specific information. We will get more accurate and relevant information.
	RAG and Fine tuning are used to get more relevant information. RAG is a prompt based method with relevant information, Fine tuning is a training a 
		model with relevant information to get relevant style of answer.
	Some companies use pretraining, which will cost more. RAG and Fine tuning are cheaper.

Pretraining:
	General purpose LLM are trained with Billions of data from internet, many developer are worked on it and spend lot of money to develop.
	When we try to build a LLM for specific application, the data training will be related to specific field only, not about general knowledge of other. So,
		accuracy of response will be more when compare with general purpose LLM.
	Now there are many specific purpose LLM are there, let see how to choose the LLM.
	
Choosing a model:
	Choosing a right model is important for efficiency, cost and performance. 
	It can be choose by two ways:
		Model size,
		Open or Closed source.
	Model Size:
		1B parameters - Pattern matching and basic knowledge of the world - restaurant reviews.
		10B parameters - Greater world knowledge. Can follow basic instructions - Food order chatbot.
		100B parameters - Rich world knowledge. Complex reasoning - Brainstorming partner.
	Open or Closed source:
		Closed source are easy to use in apps, more powerful models, relative inexpensive, some risk of vendor lock-in.
		Open source are full control over model, can run on own machine, full control over data privacy/access.
	
How LLMs follow instructions: Instructions tuning and RLHF:
	LLMs can perform not only answering the question, it can also follow instructions. Let see how it is working.
	How do chat systems learn to follow instructions:
		Pretraining with content like My favourite food is a bagel with cheese cream to predict next word.
		If we give question like what is the capital of France?, the next word prediction is what is the capital of Germany?
		Instead of predicting next word, we need answer the prompt. it can be achieved by instruction-tuning.
		Instruction tuning will tune the instruction by seting some examples by user to get answer for the question  instead of prediction of next word.
	Reinforcement Learning from Human Feedback(RLHF):
		Expecting the response will Honest, Harmless and Helpful.
		After the response comes from the LLM are reviewed and scored. Based on the high scores, the LLMs are trained with high scores to perform well.
		
Tool use and agents:
	Tools used for food order taking:
		Suppose if we order burger in the chatbot, after sometimes it will response as order have been taken. Before the response send, it will order the
			burger for us, by internally calling the create order api or function to order. To help customer, after we prompt to order burger, one modal will
			come to confirm the user to proceed further. After confirmation, order will be created and success message will display in screen as response.
	Tools for reasoning:
		If we ask for mathemathical problem, LLMs don't know the mathemathical problem to solve, it only knows to predict the next word or to respond to 
			commands. It will internally call the calculator method to solve the problem. That will give the response and then replace the value in the response.
	Agents:
		Use LLM to choose and carry out complex sequence of actions.
		Cutting edge areas of AI research.
		Eg. If we ask for prompt for list of burger competitors. It will create a steps to get the details.
			Search burger competitors,
			Visit the list of websites recommended by engine,
			For each competitor, write a summary based on the main page.
		This is the set of instructions will be created, then the agent will perform the actions to give the response.
		
Week 3 Introduction:
Generative AI and business:
Day-to-day usage of web UI LLMs:
	Writing Assistant: Writing a professional business report for the customer.
	Marketer: use brainstorming ideas to email campaign.
	Recruiter: write review about the candidate with efficient way.
	Programmer: asking to write a code to solve their problem.
	
Task analysis of jobs:
	AI can automate a task, not automate the job.
	Augmented vs Automation:
		Augmented means task will be performed by model with the help of human. Eg. suggestion while typing email.
		Automation means task will be performed by model alone. Eg. review mail auto-generated and send by system.
	Most of the jobs are initially augmented, and tested multiple way, then it is automated completely.
	A job will have lot of tasks. Eg. if we are developer, there are multiple works to do. In that, we can analyze what are the task can be automate by
		AI, what are the possibility and difficulties? Based on the ranking of task, we can automate it.
	Analysing the possiblity of task can be of two major type:
		Technical feasibility - Can AI do it? what are the other steps need to perform it?
		Business Value - Will it help to my business by reducing the time and improve the efficiency? How long will it take to complete? How much dependency 
			will reduce if we implement it? Like multiple question need to check.
	Job databases: breaking down the job roles to tasks:
		In job description, we have set of tasks to perform, we can try to augment or automate the any one of the task to improve.

Additional job analysis examples:
	Every human is doing some specific jobs. Eg. Programmer will develop apps, Doctor will cure disease, Lawyer will argue in court etc..
	Like that, specific AI will be developed to perform well in specific task or jobs will give more advantage.
	In specific jobs, we need to know the number of tasks performed and analyse what are the tasks can be replaced by AI by automated or augmented way.
	Eg. Programmer, Lawyer, Lanscaper.
	Mostly AI is used to cost saving purpose, When we try to use AI, we will think in different way so that we will get more idea to improve the task as 
		well as we can do efficient task. If we don't plan properly, then cost of developing AI to the task will become more.

New workflows and new opportunities:
	AI is used for time efficient and cost efficient. Here are some workflows and opportunities to implement Gen AI.
	Eg. Surgeon - Without GenAI, research medical procedure will take more to analyse the patient conditions and the procedure and then surgery will happen.
				- With GenAI, research medical procedure will be trained in RAG approach, so that Gen AI will give faster result of procedure and then surgery
					will happen.
		Lawyer 	- Without GenAI, Legal document review will happen by gather information, reviews documents, give client feedback.
				- With GenAI, Legal document review will happen by gather information, reviews documents by GenAI and then give client feedback will happen.
				The above flow is for complex docments, for simple documents, reviews documents as well as client feedback will be automated or augmented.
		Marketing - Without GenAI, marketing automation will be done by write website copy and push to website.
				  - With GenAI, marketing automation will be done by write website copy by GenAI and push to website.
			Test and analyze multiple version of application to choose the best one to improve prompts.
		Analysing customer task - Helping customer building websites. First, split the task one by one to build websites, analyze each thing and score the
			possibility of each task and based on high score, try to automate or augment the task.
	Time consumption of AI will be much lesser than the manual task done by human.

Teams to build generative AI software:
	Big team needs a set of roles to build generative AI software.
	Roles:
		Software Engineer: know how to develop software and need to learn basic of prompting and LLM concepts.
		Machine Learning Engineer: know how to implement the AI and ML algorithms and models as well as better idea of prompting, LLM, fine tuning and RAGs.
		Product Manager: know the scope and value of product and business.
		Prompt Engineer: know how to prompt to LLM models to get desire output.
	Prompt Engineer are over hyped by social media, but actually it is not like that. The role is taken in some companies and their task is not only do
		prompt, they also have to ML and other tasks.
	Small Teams:
		One person:
			ML engineer can learn some basic software building skills and start work on it.
			Software engineer can learn some basic LLM and prompting concepts to develop AI softwares.
			Yourself can start learn on basic of software and LLM and prompting concepts to develop AI softwares.
		Two person:
			This is the best combo to develop AI applications. A ML Engineer and Software Engineer.
	Other Roles:
		Data Engineer: know to collect and organize datas.
		Data Scientist: know to analyze and give suggestion or recommendation to clients or compnay.
		Product Manager: responsible for execution of project.
		ML Researcher: responsible for developing advanced AI technologies.

Automation potential across sectors:
	According to the analysis, Genearative AI will create high paid jobs in future than current high paid jobs.
	A graph show the analysis of functional role and impacts of billions vs impact % of functional spend. It shows that most of the customer services, IT 
		industry related jobs will be more impacted by Gen AI than other functional roles in other sectors.
	There is a list of sectors which show the impacts of Gen AI, Majority of software(knowledge related works) are going to replace by GenAI then other 
		industrial works.

Generative AI and Society:
Concerns about AI:
	1) Amplifies human's worst impulses:
		Gen AI are collects and learned from lot of data available from internet. Internet will have both good and bad things of human activities. So, AI
			learned from internet can do human's mistakes and worst things. Eg. The __ is the CEO. It will give man as answer. But it can be woman also.
			This can be resolved by advanced techniques like fine tuning and RLHF. From RLHF, we get human feedback about the answer and the scores are
			provided, based on the high scores model will train again to respond better.
	2) Job loss:
		Jobs are automated by AIs. But complete job can't be automated, few task can be made. So, don't worry about the job loss. But normal specific employee 
			can be replaced by AI known specific employee for effective tasks.
		AI will not create job loss, it will create more jobs than now. Think we initially used Calculating Machine > Big computers > PC > Laptops > Mobiles.
			Since the jobs during big computers are lesser when compared to current jobs. As evolution, jobs also evolve with more opportunities.
	3) Human Extinction:
		As the evolution goes, Human extinction will not going to loss. AI is just a technology, we are going to use it for our productivity, not to replace us.
		Eg. When aeroplanes were created, lot of accidents and faults were happened. We didn't stop the use of aeroplanes, we learn from the mistakes and
			correct it make use of it in proper way. Like that, we will learn from AI to use effectively.
	
Artificial General Intelligence:
	AGI is an AI can do task which are done by human, but we are very far from the technology. It will more decades to achieve. But it is possible.
	Currently, Some tasks are performed better by AI than human. But it can't do all the tasks.
	Eg. it can learn driving in less than 20hrs which can be done by human. It can do PhD as human can do. Still, lot of training are going for self-driving cars.
	Large Language Model like ChatGPT are used for general purpose, it is not general intelligence.
	Still AI is very powerful than human, we have to make use of it properly.
	AGI is still development because it is benchmarked with human.
	
Responsible AI:
	Dimensions of Responsible AI:
		Fairness: ensuring AI should not amplify human biases.
		Transparent: decisions made by AI should be understandable by stackholders or users.
		Security: safeguard AI system from malicious attack.
		Privacy: protecting user data and ensure confidentiality.
		Ethical use: ensuring AI is used for beneficial purposes.
	Tips for responsible AI:
		build a culture that encourages discuss and debate on ethical usages.
		brainstorm things that goes wrong. Eg. dimensions of responsible AI.
		work with diverse team and include prespective from all the team.

Course Summary:
	On first week, we learned about:
		what is GenAI?
		what can and can't do?
		common use cases: writing, prompting, chatting.
	On second week, we learned about:
		workflow of GenAI projects.
		advanced techniques like fine tuning and RAG approaches.
	On third week, we learned about:
		Implication of Society and business.
		Analysing tasks in jobs for automation or augmentation potential.
		Concern about AI and responsible AI.
		
Building a more intelligent system:
	Humans are educated from child to make decisions on their own and the way they learning are valuable and teach will know the condition of a child and
		know how to teach him/her. A doctor will further analyze and give the proper solution for the disease which he learned from his experience. Everyone 
		is fearing about AI, think about Electricity when it came, everyone feared same as AI, but now all are using it and adaptable to it, now no one is 
		ready to avoid electricity for the fear they have. Still electricity is very powerful, they learned to use wisely, same will happen for AI also. AI 
		will make a remarkable place in our life.
</pre>
    </body>
    </html>
    