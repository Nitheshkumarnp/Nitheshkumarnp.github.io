<html>
    <head>
        <title>
            Complete Profile
        </title>
        <link rel="stylesheet" href="../style.css">
    </head>
    <>
        <h1>Let's start</h1>
        <div class="flex bg-black font-white">
            <h1 class="pd-5-15 mr-0" onclick="document.location='../MachineLearning/MachineLearning.html'">
                Machine learning</h1>
            <div class="gap"></div>
            <h1 class="pd-5-15 mr-0" onclick="document.location='../Python/python.html'">Python</h1>
            <div class="gap"></div>
            <h1 class="pd-5-15 mr-0" onclick="document.location='../Algorithms/Algorithms.html'">
                ML Algorithms</h1>
        </div>
        <div>
          <h4>Linear Regression</h4>
          <h4>What is linear regression?</h4>
          <p>&nbsp;&nbsp;&nbsp;Linear Regression is the supervised Machine Learning model 
          in which the model finds the best fit linear line between the independent and 
          dependent variable i.e it finds the linear relationship between the dependent 
          and independent variable.</p>
          <h4>Why:</h4>
          <p>&nbsp;&nbsp;&nbsp;predicts continuous values.</p>
          <p>&nbsp;&nbsp;&nbsp;The goal of is to adjust the values of the model's 
          parameters to find the line or curve that comes closest to your data. For example,
           with linear regression, the goal is to find the best-fit values of the slope and 
          intercept that makes the line come close to the data.</p>
          <h4>How:</h4>
          <p>&nbsp;&nbsp;&nbsp;OLS or Ordinary Least Squares is a method used in Linear 
          Regression for estimating the unknown parameters by creating a model which will 
          minimize the sum of the squared errors between the observed data and the predicted 
          one.<br>
          &nbsp;&nbsp;&nbsp;Ordinary Least Squares regression (OLS) is a common technique 
          for estimating coefficients of linear regression equations which describe the 
          relationship between one or more independent quantitative variables and a 
          dependent variable (simple or multiple linear regression).</p>
          <h4>Types:</h4>
          <p>&nbsp;&nbsp;&nbsp;Simple Linear Regression</p>
          <p>&nbsp;&nbsp;&nbsp;Multiple Linear Regression</p>
          <h4>Simple Linear Regression</h4>
          <p>&nbsp;&nbsp;&nbsp;It finds relationship between one input variable and output 
          variable.</p>
          <h4>Multiple Linear Regression</h4>
          <p>&nbsp;&nbsp;&nbsp;It finds relationship between two or more input variables 
          and output variable.</p>
          <h4>Equations:</h4>
          <p>&nbsp;&nbsp;&nbsp;Simple Linear Regression equation: y = b0+b1x<br>
          &nbsp;&nbsp;&nbsp;Multiple Linear Regression equation: y= b0+b1x+ b2x2+ 
          b3x3+....+ bnxn</p>
          <h4>Assumptions:</h4>
          <p>&nbsp;&nbsp;&nbsp;<b>Independence of observations : </b>Independence means that 
          there is no relation between the different examples. There should no duplicate 
          datas.<br>&nbsp;&nbsp;&nbsp;<b>No Hidden or Missing Variables : </b>you have used 
          all relevant explanatory variables in your model. If you do not do this, you end 
          up with a wrong model.<br>&nbsp;&nbsp;&nbsp;<b>Relationship : </b>Relations 
          between the independent and dependent variables must be linear.You can check for 
          linear relationships easily by making a scatter plot for each independent 
          variable with the dependent variable.<br>&nbsp;&nbsp;&nbsp;<b>Normality of the 
          residuals : </b>Residuals should follow a normal distribution.<br>
          &nbsp;&nbsp;&nbsp;No or little Multicollinearity. <br>&nbsp;&nbsp;
          Homoscedasticity</p>
          <h4>Advantages: </h4>
          <p>&nbsp;&nbsp;&nbsp;Linear regression performs exceptionally well for linearly 
          separable data.<br>&nbsp;&nbsp;&nbsp;Easier to implement, interpret and efficient 
          to train.<br>&nbsp;&nbsp;&nbsp;It handles overfitting pretty well using 
          dimensionally reduction techniques, regularization, and cross-validation.<br>
          &nbsp;&nbsp;&nbsp;Extrapolation beyond a specific data set.</p>
          <h4>Disdvantages: </h4>
          <p>&nbsp;&nbsp;&nbsp;It is often quite prone to noise and overfitting.<br>
          &nbsp;&nbsp;&nbsp;Linear regression is quite sensitive to outliers.<br>
          &nbsp;&nbsp;&nbsp;It is prone to multicollinearity.</p>
          <h4>Evaluation Metrics: </h4>
          <p>&nbsp;&nbsp;&nbsp;MAE<br>&nbsp;&nbsp;&nbsp;MSE<br>&nbsp;&nbsp;&nbsp;RMSE</p>
      </div>
    </body>
</html>
