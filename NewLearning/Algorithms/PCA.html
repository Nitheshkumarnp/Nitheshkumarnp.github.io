<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PCA Concepts</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 5px 20px;
            background-color: #f4f4f9;
        }
        .containers {
            margin: auto;
            background: #fff;
            padding: 10px 15px;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        h1 {
            text-align: center;
            color: #333;
            margin: 0px;
            font-size: 20px;
        }
        h2 {
            color: #555;
            margin: 0px;
            font-size: 16px;
        }
        p {
            margin: 0 0 0 20px;
            color: #666;
            font-size: 14px;
        }
        ul {
            margin: 0;
        }
        li {
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="containers">
        <h1>Principal Component Analysis</h1>
        
        <h2>Introduction:</h2>
        <p>* PCA is a statistical technique used for reducing the dimensionality of a dataset while preserving as much variance as possible.It transforms the original variables into a new set of uncorrelated variables called principal components, which are ordered by the amount of variance they capture from the data.</p>
        <p>* It is primarily used to transform high-dimensional datasets into a lower-dimensional space while preserving the most important information in the data.</p>
        <p>* The main goal of PCA is to find a set of new variables, called principal components, that are linear combinations of the original variables. These principal components are orthogonal to each other and capture the maximum amount of variance in the data. The first principal component accounts for the largest possible variance, and each succeeding component explains the remaining variance in decreasing order.</p>
  
        <h2>Applications:</h2>
        <li>Data Compression: Reducing the number of features while retaining important information.</li>
        <li>Noise Reduction: Removing less significant components to reduce noise.</li>
        <li>Data Visualization: Reducing high-dimensional data to 2 or 3 dimensions for visualization.</li>
        <li>Feature Extraction: Identifying new variables that are linear combinations of the original variables.</li>
    </div>
</body>
</html>
